# EcDNet-Encoder-Corollary-Atrous-Spatial-Pyramid-Pooling-Decoder-Automated-for-Pancreas-Segmentation-
RESEARCH WORK: EcD-Net: Encoder-Corollary Atrous Spatial Pyramid Pooling-Decoder Network for Automated Pancreas Segmentation of 2D CT Images With Attention Mechanisms



Abstract: For the purposes of diagnosis, prognosis, surgical planning, and intra-operative guidance, segmentation of the pancreas using CT images assists physicians in detection aberrant volume changes and tracking growth anomalies. It is extremely difficult to automatically segment the pancreas due to its size and position in the CT image input data, which confounds deep segmentation networks due to the complexity of the background region. To solve this difficulty, we propose the Encoder-Corollary Atrous Spatial Pyramid Pooling-Decoder Network (EcD-Net) for locating and segmenting the pancreas. This two-tiered method begins with a coarse segmentation stage for locating the pancreas within the overall CT image. Using the detected image from the first tier, a fine segmentation network is applied to precisely segment the target organ (pancreas). We present a novel Saturated Multi-view Dense Module (SMD-Module) to enhance information gradient flow in order to stabilize the training process so as to make convergence much easier at the fine stage and a novel Corollary Atrous Spatial Pyramid Pooling Module (CASPP-Module) to capture low level details and high-level global context information concurrently to enhance the pancreas segmentation accuracy and extract global and local spatial data and to detect the pancreas at varied scales. On the publicly available National Institute of Health (NIH) pancreatic dataset, our proposed method surpasses previous state-of-the-art methods with a mean Dice Similarity Coefficient (DSC) of 87.85%, mean Precision (PRE), Recall (REC), and Intersection over Union (IoU) of 89.60%, 86.18%, and 89.12% respectively, and it also records
the lowest standard deviations showing the robustness and steadiness of our proposed method.
